{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f77825-9dcf-465b-baf6-99835f370b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "class one2three(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(one2three,self).__init__()\n",
    "        self.upscale  = nn.Upsample(size=(500,500),mode='bilinear',align_corners=True)\n",
    "        self.backbone = torchvision.models.mobilenet_v3_small(pretrained= True)\n",
    "        \n",
    "        for name,param in self.backbone.named_parameters():\n",
    "            if 'classifier' not in name:\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.backbone.classifier[3] = nn.Linear(1024,10)\n",
    "        self.softmax  = nn.Softmax(dim=1)\n",
    "    def forward(self,x):\n",
    "        x = torch.cat([x]*3,dim=1)\n",
    "        x = self.upscale(x)\n",
    "        x = self.backbone(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from random import random\n",
    "class dark(pl.LightningModule):\n",
    "    def __init__(self, classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = one2three()\n",
    "        self.loss  = nn.CrossEntropyLoss()\n",
    "    def forward(self,x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.loss(y_hat, y)\n",
    "        tensorboard_logs = {'train_loss': loss.item()}\n",
    "        \n",
    "        if batch_idx %10 ==0:\n",
    "            l = loss.item() \n",
    "            self.log(\"killer\",  {\"acc\": l, \"recall\": l + random(),'F1':l+random() })\n",
    "            self.log(\"killer/child0\",  {\"acc\": l, \"recall\": l + random(),'F1':l+random() })\n",
    "        return {'loss': loss , 'log': tensorboard_logs}\n",
    "    def training_epoch_end(self,training_step_outputs):\n",
    "        for out in training_step_outputs:\n",
    "            l = out['loss']\n",
    "            self.log('epoch_test',{'loss':l,'kk':l+random()})\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "model = dark()\n",
    "\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "seed_everything(0)\n",
    "\n",
    "# data\n",
    "mnist_train = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_train = DataLoader(mnist_train, batch_size=320, num_workers=12)\n",
    "mnist_val = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_val = DataLoader(mnist_val, batch_size=320, num_workers=12)\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "tb_logger = pl_loggers.TensorBoardLogger(\"/aiv-data/tfboard\")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,logger=[tb_logger],progress_bar_refresh_rate=20,max_epochs=10 ) # gpus=[0,1],accelerator='ddp')\n",
    "trainer.fit(model,mnist_train,mnist_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor1.9",
   "language": "python",
   "name": "tor1.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
