{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-attraction",
   "metadata": {},
   "source": [
    "### load & save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "\n",
    "model.save('my_model.h5')\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-retail",
   "metadata": {},
   "source": [
    "### model_selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# 10개의 파일로 쪼갬\n",
    "n_fold = 2\n",
    "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "for train, test in skf.split(X, Y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
    "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
    "    accuracy.append(k_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strong-branch",
   "metadata": {},
   "source": [
    "### - callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-interpretation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "# epoch val_accuracy val_loss\n",
    "modelpath=\"./model/{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-deviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "### tensorboard\n",
    "import tensorflow as tf # !taskkill -pid  16224 /f\n",
    "%load_ext tensorboard \n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])\n",
    "%tensorboard --logdir logs/fit --port 6006\n",
    "!tensorboard dev upload \\\n",
    "  --logdir logs/fit \\\n",
    "  --name \"(optional) My latest experiment\" \\\n",
    "  --description \"(optional) Simple comparison of several hyperparameters\" \\\n",
    "  --one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "### list\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "callback_list = [\n",
    "  keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', # 모델의 검증 정확도 모니터링\n",
    "    patience=1, # 1 에포크보다 더 길게 향상되지 않으면 중단\n",
    "  ),\n",
    "  keras.callbacks.ModelCheckpoint(\n",
    "    filepath='my_model.h5', # 저장\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True, # 가장 좋은 모델\n",
    "  ),\n",
    "  keras.callbacks.ReduceLROnPlateau(\n",
    "  monitor='val_loss',\n",
    "  factor=0.1, # 콜백이 호출되면 학습률을 10배로 줄임\n",
    "  patience=10,\n",
    "  ),\n",
    "  tensorboard_callback\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=200, verbose=0, callbacks=[early_stopping_callback,checkpointer])\n",
    "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-raleigh",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨볼루션 신경망의 설정\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), input_shape=(28, 28, 1), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,  activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-looking",
   "metadata": {},
   "source": [
    "### GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU, UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#이미지가 저장될 폴더가 없다면 만듭니다.\n",
    "import os\n",
    "if not os.path.exists(\"./gan_images\"):\n",
    "    os.makedirs(\"./gan_images\")\n",
    "\n",
    "np.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "#생성자 모델을 만듭니다.\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "#판별자 모델을 만듭니다.\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=5, strides=2, input_shape=(28,28,1), padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False\n",
    "\n",
    "#생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "gan.summary()\n",
    "\n",
    "#신경망을 실행시키는 함수를 만듭니다.\n",
    "def gan_train(epoch, batch_size, saving_interval):\n",
    "\n",
    "  # MNIST 데이터 불러오기\n",
    "\n",
    "  (X_train, _), (_, _) = mnist.load_data()  # 앞서 불러온 적 있는 MNIST를 다시 이용합니다. 단, 테스트과정은 필요없고 이미지만 사용할 것이기 때문에 X_train만 불러왔습니다.\n",
    "  X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "  X_train = (X_train - 127.5) / 127.5  # 픽셀값은 0에서 255사이의 값입니다. 이전에 255로 나누어 줄때는 이를 0~1사이의 값으로 바꾸었던 것인데, 여기서는 127.5를 빼준 뒤 127.5로 나누어 줌으로 인해 -1에서 1사이의 값으로 바뀌게 됩니다.\n",
    "  #X_train.shape, Y_train.shape, X_test.shape, Y_test.shape\n",
    "\n",
    "  true = np.ones((batch_size, 1))\n",
    "  fake = np.zeros((batch_size, 1))\n",
    "\n",
    "  for i in range(epoch):\n",
    "          # 실제 데이터를 판별자에 입력하는 부분입니다.\n",
    "          idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "          imgs = X_train[idx]\n",
    "          d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "          #가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "          noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "          gen_imgs = generator.predict(noise)\n",
    "          d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "          #판별자와 생성자의 오차를 계산합니다.\n",
    "          d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "          g_loss = gan.train_on_batch(noise, true)\n",
    "\n",
    "          print('epoch:%d' % i, ' d_loss:%.4f' % d_loss, ' g_loss:%.4f' % g_loss)\n",
    "\n",
    "        # 이부분은 중간 과정을 이미지로 저장해 주는 부분입니다. 본 장의 주요 내용과 관련이 없어\n",
    "        # 소스코드만 첨부합니다. 만들어진 이미지들은 gan_images 폴더에 저장됩니다.\n",
    "          if i % saving_interval == 0:\n",
    "              #r, c = 5, 5\n",
    "              noise = np.random.normal(0, 1, (25, 100))\n",
    "              gen_imgs = generator.predict(noise)\n",
    "\n",
    "              # Rescale images 0 - 1\n",
    "              gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "              fig, axs = plt.subplots(5, 5)\n",
    "              count = 0\n",
    "              for j in range(5):\n",
    "                  for k in range(5):\n",
    "                      axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                      axs[j, k].axis('off')\n",
    "                      count += 1\n",
    "              fig.savefig(\"gan_images/gan_mnist_%d.png\" % i)\n",
    "\n",
    "gan_train(4001, 32, 200)  #4000번 반복되고(+1을 해 주는 것에 주의), 배치 사이즈는 32,  200번 마다 결과가 저장되게 하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-texture",
   "metadata": {},
   "source": [
    " ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#MNIST데이터 셋을 불러옵니다.\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
    "\n",
    "#생성자 모델을 만듭니다.\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# 인코딩 부분입니다.\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "\n",
    "# 디코딩 부분이 이어집니다. \n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n",
    "\n",
    "# 전체 구조를 확인해 봅니다.\n",
    "autoencoder.summary()\n",
    "\n",
    "# 컴파일 및 학습을 하는 부분입니다.\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, validation_data=(X_test, X_test))\n",
    "\n",
    "#학습된 결과를 출력하는 부분입니다.\n",
    "random_test = np.random.randint(X_test.shape[0], size=5)  #테스트할 이미지를 랜덤하게 불러옵니다.\n",
    "ae_imgs = autoencoder.predict(X_test)  #앞서 만든 오토인코더 모델에 집어 넣습니다.\n",
    "\n",
    "plt.figure(figsize=(7, 2))  #출력될 이미지의 크기를 정합니다.\n",
    "\n",
    "for i, image_idx in enumerate(random_test):    #랜덤하게 뽑은 이미지를 차례로 나열합니다.\n",
    "   ax = plt.subplot(2, 7, i + 1) \n",
    "   plt.imshow(X_test[image_idx].reshape(28, 28))  #테스트할 이미지를 먼저 그대로 보여줍니다.\n",
    "   ax.axis('off')\n",
    "   ax = plt.subplot(2, 7, 7 + i +1)\n",
    "   plt.imshow(ae_imgs[image_idx].reshape(28, 28))  #오토인코딩 결과를 다음열에 출력합니다.\n",
    "   ax.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
